{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 260587899 Lim, Dongjoon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and define useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For a movie that gets no respect there sure ar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bizarre horror movie filled with famous faces ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A solid, if unremarkable film. Matthau, as Ein...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's a strange feeling to sit alone in a theat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You probably all already know this by now, but...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  For a movie that gets no respect there sure ar...  1\n",
       "1  Bizarre horror movie filled with famous faces ...  1\n",
       "2  A solid, if unremarkable film. Matthau, as Ein...  1\n",
       "3  It's a strange feeling to sit alone in a theat...  1\n",
       "4  You probably all already know this by now, but...  1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import collections, re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def F1score(classifier, testFeature, testTarget, trainFeature, trainTarget, validFeature, validTarget, name):\n",
    "    classifier.fit(trainFeature,trainTarget)\n",
    "    predicted_test = classifier.predict(testFeature)\n",
    "    predicted_train =classifier.predict(trainFeature)\n",
    "    predicted_valid =classifier.predict(validFeature)\n",
    "    f1_test = f1_score(testTarget,predicted_test, average='macro')\n",
    "    f1_train = f1_score(trainTarget,predicted_train, average='macro')\n",
    "    f1_valid = f1_score(validTarget,predicted_valid, average='macro')\n",
    "    #bestParam = classifier.best_params_\n",
    "    print('Below is f1 scores and best parameter for '+str(name))\n",
    "    print('f1 score for yelp {} classifier test is: {}'.format(name, f1_test))\n",
    "    print('f1 score for yelp {} classifier train is: {}'.format(name, f1_train))\n",
    "    print('f1 score for yelp {} classifier valid is: {}'.format(name, f1_valid))\n",
    "    print('====================================================================================')\n",
    "    #print('Best parameter is: '.format(bestParam))\n",
    "    return f1_valid\n",
    "def F1score2(classifier, testFeature, testTarget, trainFeature, trainTarget, validFeature, validTarget, name):\n",
    "    classifier.fit(trainFeature,trainTarget)\n",
    "    bestParam = classifier.best_params_\n",
    "    result= classifier.cv_results_\n",
    "    predicted_test = classifier.predict(testFeature)\n",
    "    predicted_train =classifier.predict(trainFeature)\n",
    "    predicted_valid =classifier.predict(validFeature)\n",
    "    f1_test = f1_score(testTarget,predicted_test, average='macro')\n",
    "    f1_train = f1_score(trainTarget,predicted_train, average='macro')\n",
    "    f1_valid = f1_score(validTarget,predicted_valid, average='macro')\n",
    "    \n",
    "    print('Below is f1 scores and best parameter for '+str(name))\n",
    "    print('f1 score for yelp {} classifier test is: {}'.format(name, f1_test))\n",
    "    print('f1 score for yelp {} classifier train is: {}'.format(name, f1_train))\n",
    "    print('f1 score for yelp {} classifier valid is: {}'.format(name, f1_valid))\n",
    "    print('Best parameter is: {}'.format(bestParam))\n",
    "    print('====================================================================================')\n",
    "    return f1_valid\n",
    "\n",
    "def F1score3(classifier, testFeature, testTarget, trainFeature, trainTarget, validFeature, validTarget, name):\n",
    "    classifier.fit(trainFeature,trainTarget)\n",
    "    bestParam = classifier.best_params_\n",
    "    predicted_test = classifier.predict(testFeature)\n",
    "    predicted_train =classifier.predict(trainFeature)\n",
    "    predicted_valid =classifier.predict(validFeature)\n",
    "    f1_test = f1_score(testTarget,predicted_test, average='macro')\n",
    "    f1_train = f1_score(trainTarget,predicted_train, average='macro')\n",
    "    f1_valid = f1_score(validTarget,predicted_valid, average='macro')\n",
    "    \n",
    "    print('Below is f1 scores and best parameter for '+str(name))\n",
    "    print('f1 score for imdb {} classifier test is: {}'.format(name, f1_test))\n",
    "    print('f1 score for imdb {} classifier train is: {}'.format(name, f1_train))\n",
    "    print('f1 score for imdb {} classifier valid is: {}'.format(name, f1_valid))\n",
    "    print('Best parameter for {} is: {}'.format(name, bestParam))\n",
    "    print('====================================================================================')\n",
    "    return f1_valid\n",
    "def F1score4(classifier, testFeature, testTarget, trainFeature, trainTarget, validFeature, validTarget, name):\n",
    "    classifier.fit(trainFeature,trainTarget)\n",
    "    predicted_test = classifier.predict(testFeature)\n",
    "    predicted_train =classifier.predict(trainFeature)\n",
    "    predicted_valid =classifier.predict(validFeature)\n",
    "    f1_test = f1_score(testTarget,predicted_test, average='macro')\n",
    "    f1_train = f1_score(trainTarget,predicted_train, average='macro')\n",
    "    f1_valid = f1_score(validTarget,predicted_valid, average='macro')\n",
    "    #bestParam = classifier.best_params_\n",
    "    print('Below is f1 scores and best parameter for '+str(name))\n",
    "    print('f1 score for imdb {} classifier test is: {}'.format(name, f1_test))\n",
    "    print('f1 score for imdb {} classifier train is: {}'.format(name, f1_train))\n",
    "    print('f1 score for imdb {} classifier valid is: {}'.format(name, f1_valid))\n",
    "    print('====================================================================================')\n",
    "    #print('Best parameter is: '.format(bestParam))\n",
    "    return f1_valid\n",
    "\n",
    "def saveVocab(wordList, frequencyList, name):\n",
    "    with open('Generated_Data/{}-vocab.txt'.format(name),'w+') as file:\n",
    "        for i in range(10000):\n",
    "            file.write('{}\\t{}\\t{}\\n'.format(wordList[i],i,frequencyList[i]))\n",
    "\n",
    "def savedata(vocabulary, data ,name, datatype):\n",
    "    with open('Generated_Data/{}-{}.txt'.format(name, datatype),'w+') as file:\n",
    "        row =0\n",
    "        for sentence in data[0]:\n",
    "            line = ''\n",
    "            token = sentence.split(' ')\n",
    "            for piece in token:\n",
    "                id = vocabulary.get(piece)\n",
    "                #ignore if the word is not frequent.\n",
    "                if id != None:\n",
    "                    line += str(id)+ ' '\n",
    "            file.write('{}\\t{}\\n'.format(line, data[1][row])) \n",
    "            row = row+1\n",
    "\n",
    "yelp_test = pd.read_csv('Data/yelp-test.txt', header=None, sep=\"\\t\")\n",
    "yelp_train = pd.read_csv('Data/yelp-train.txt', header=None, sep=\"\\t\")\n",
    "yelp_valid = pd.read_csv('Data/yelp-valid.txt', header=None, sep=\"\\t\")\n",
    "\n",
    "imdb_train = pd.read_csv('Data/IMDB-train.txt', header=None, sep=\"\\t\")\n",
    "imdb_valid = pd.read_csv('Data/IMDB-valid.txt', header=None, sep=\"\\t\")\n",
    "imdb_test = pd.read_csv('Data/IMDB-test.txt', header=None, sep=\"\\t\")\n",
    "\n",
    "#Sanity check\n",
    "yelp_train.head()\n",
    "imdb_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 Preprocess data and vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "#Removing punctuations and change capital to lower case\n",
    "yelp_train[0] = yelp_train[0].str.replace('<br /><br />', ' ').str.replace('[^\\w\\s]', '').str.lower()\n",
    "yelp_test[0] = yelp_test[0].str.replace('<br /><br />', ' ').str.replace('[^\\w\\s]', '').str.lower()\n",
    "yelp_valid[0] = yelp_valid[0].str.replace('<br /><br />', ' ').str.replace('[^\\w\\s]', '').str.lower()\n",
    "imdb_train[0] = imdb_train[0].str.replace('<br /><br />', ' ').str.replace('[^\\w\\s]', '').str.lower()\n",
    "imdb_test[0] = imdb_test[0].str.replace('<br /><br />', ' ').str.replace('[^\\w\\s]', '').str.lower()\n",
    "imdb_valid[0] = imdb_valid[0].str.replace('<br /><br />', ' ').str.replace('[^\\w\\s]', '').str.lower()\n",
    "\n",
    "#Make bag of words\n",
    "vectorizer = CountVectorizer(max_features = 10000)\n",
    "\n",
    "yelpTrain = vectorizer.fit_transform(yelp_train[0])\n",
    "yelpTest = vectorizer.transform(yelp_test[0])\n",
    "yelpValid = vectorizer.transform(yelp_valid[0])\n",
    "\n",
    "vocabulary = vectorizer.vocabulary_\n",
    "wordList = vectorizer.get_feature_names()\n",
    "frequencyList = np.asarray(yelpTrain.sum(axis=0))[0]\n",
    "\n",
    "saveVocab(wordList, frequencyList, 'yelp')\n",
    "savedata(vocabulary, yelp_train ,'yelp', 'train')\n",
    "savedata(vocabulary, yelp_test ,'yelp', 'test')\n",
    "savedata(vocabulary, yelp_valid ,'yelp', 'valid')\n",
    "\n",
    "imdbTrain = vectorizer.fit_transform(imdb_train[0])\n",
    "imdbTest = vectorizer.transform(imdb_test[0])\n",
    "imdbValid = vectorizer.transform(imdb_valid[0])\n",
    "\n",
    "vocabulary = vectorizer.vocabulary_\n",
    "wordList = vectorizer.get_feature_names()\n",
    "frequencyList = np.asarray(yelpTrain.sum(axis=0))[0]\n",
    "\n",
    "saveVocab(wordList, frequencyList, 'IMDB')\n",
    "savedata(vocabulary, imdb_train ,'IMDB', 'train')\n",
    "savedata(vocabulary, imdb_test ,'IMDB', 'test')\n",
    "savedata(vocabulary, imdb_valid ,'IMDB', 'valid')\n",
    "\n",
    "#Normalize to get frequency bag of words that frequencies sums up to 1\n",
    "normal = Normalizer()\n",
    "\n",
    "yelpTrain_freq = normal.transform(yelpTrain)\n",
    "yelpTrain_freq = yelpTrain_freq/yelpTrain_freq.sum()\n",
    "yelpTest_freq = normal.transform(yelpTest)\n",
    "yelpTest_freq = yelpTest_freq/yelpTest_freq.sum()\n",
    "yelpValid_freq = normal.transform(yelpValid)\n",
    "yelpValid_freq = yelpValid_freq/yelpValid_freq.sum()\n",
    "imdbTrain_freq = normal.transform(imdbTrain)\n",
    "imdbTrain_freq = imdbTrain_freq/imdbTrain_freq.sum()\n",
    "imdbTest_freq = normal.transform(imdbTest)\n",
    "imdbTest_freq = imdbTest_freq/imdbTest_freq.sum()\n",
    "imdbValid_freq = normal.transform(imdbValid)\n",
    "imdbValid_freq = imdbValid_freq/imdbValid_freq.sum()\n",
    "print(type(yelpTrain))\n",
    "\n",
    "\n",
    "\n",
    "#sanity check\n",
    "#print(yelpTrain_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2, train models and perform hyperparameter tuning to get f1 measures. Binary Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is f1 scores and best parameter for uniform\n",
      "f1 score for yelp uniform classifier test is: 0.17520594816848462\n",
      "f1 score for yelp uniform classifier train is: 0.18336811298204822\n",
      "f1 score for yelp uniform classifier valid is: 0.1880367210174599\n",
      "====================================================================================\n",
      "Below is f1 scores and best parameter for majority frequent\n",
      "f1 score for yelp majority frequent classifier test is: 0.10392301998519615\n",
      "f1 score for yelp majority frequent classifier train is: 0.10426700464723279\n",
      "f1 score for yelp majority frequent classifier valid is: 0.10501474926253689\n",
      "====================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongjoon/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is f1 scores and best parameter for Naive Bayes\n",
      "f1 score for yelp Naive Bayes classifier test is: 0.38115077661846924\n",
      "f1 score for yelp Naive Bayes classifier train is: 0.7292359932480867\n",
      "f1 score for yelp Naive Bayes classifier valid is: 0.3702751079974438\n",
      "Best parameter is: {'alpha': 0.09}\n",
      "====================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongjoon/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is f1 scores and best parameter for Decision Tree\n",
      "f1 score for yelp Decision Tree classifier test is: 0.23318797392174656\n",
      "f1 score for yelp Decision Tree classifier train is: 0.2742832668464026\n",
      "f1 score for yelp Decision Tree classifier valid is: 0.26490158061164243\n",
      "Best parameter is: {'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': 19, 'min_samples_split': 2}\n",
      "====================================================================================\n",
      "Below is f1 scores and best parameter for Linear Support Vector Machine\n",
      "f1 score for yelp Linear Support Vector Machine classifier test is: 0.4075051599519378\n",
      "f1 score for yelp Linear Support Vector Machine classifier train is: 0.9875560114861116\n",
      "f1 score for yelp Linear Support Vector Machine classifier valid is: 0.4358022431846056\n",
      "Best parameter is: {'C': 0.5, 'loss': 'squared_hinge', 'max_iter': 60}\n",
      "====================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4358022431846056"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform = DummyClassifier(strategy='uniform', random_state=100) #set random seed so we get consistent results\n",
    "frequent = DummyClassifier(strategy='most_frequent')\n",
    "Nbayes_grid = [\n",
    "    {\n",
    "        'alpha' : np.arange(0.01, 0.3, 0.01)\n",
    "    }\n",
    "]\n",
    "Nbayes = GridSearchCV(BernoulliNB(), Nbayes_grid, cv=5,scoring='f1_micro', refit = True)\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "     FunctionTransformer(lambda x: x.todense(), accept_sparse=True), \n",
    "     GaussianNB()\n",
    ")\n",
    "gauss_grid = {}\n",
    "GaussNbayes = GridSearchCV(pipeline, gauss_grid, cv=5,scoring='f1_micro', refit = True)\n",
    "\n",
    "dt_grid = [\n",
    "    {\n",
    "        'criterion':['gini','entropy'], \n",
    "        'max_leaf_nodes': [18,19,20,21,22],\n",
    "        'max_depth':[8,9,10,11,12],\n",
    "        'min_samples_split':[2,3,4,5,6]\n",
    "    }\n",
    "]\n",
    "DecisionTree = GridSearchCV(DecisionTreeClassifier(), dt_grid, cv=5,scoring='f1_micro', refit = True)\n",
    "\n",
    "svc_grid = [\n",
    "    {\n",
    "        'max_iter': [15 * i for i in range(5)],\n",
    "        'loss':['hinge','squared_hinge'],\n",
    "        'C':[0.5,1.0,2.0,3.0]\n",
    "    }\n",
    "]\n",
    "svc = GridSearchCV(LinearSVC(), svc_grid, cv=5,scoring='f1_micro', refit = True)\n",
    "#print(type(yelpTest))\n",
    "#print(type(yelp_test[1]))\n",
    "F1score(uniform, yelpTest, yelp_test[1], yelpTrain, yelp_train[1], yelpValid, yelp_valid[1], 'uniform')\n",
    "F1score(frequent, yelpTest, yelp_test[1], yelpTrain, yelp_train[1], yelpValid, yelp_valid[1], 'majority frequent')\n",
    "\n",
    "F1score2(Nbayes, yelpTest, yelp_test[1], yelpTrain, yelp_train[1], yelpValid, yelp_valid[1], 'Naive Bayes')\n",
    "F1score2(DecisionTree, yelpTest, yelp_test[1], yelpTrain, yelp_train[1], yelpValid, yelp_valid[1], 'Decision Tree')\n",
    "F1score2(svc, yelpTest, yelp_test[1], yelpTrain, yelp_train[1], yelpValid, yelp_valid[1], 'Linear Support Vector Machine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3, train models and perform hyperparameter tuning to get f1 measures. Frequent Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is f1 scores and best parameter for Naive Bayes\n",
      "f1 score for yelp Naive Bayes classifier test is: 0.24399044080292537\n",
      "f1 score for yelp Naive Bayes classifier train is: 0.722856822871117\n",
      "f1 score for yelp Naive Bayes classifier valid is: 0.2841059259835029\n",
      "Best parameter is: {}\n",
      "====================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongjoon/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is f1 scores and best parameter for Decision Tree\n",
      "f1 score for yelp Decision Tree classifier test is: 0.24299026355849002\n",
      "f1 score for yelp Decision Tree classifier train is: 0.26996428201753997\n",
      "f1 score for yelp Decision Tree classifier valid is: 0.2502904291095359\n",
      "Best parameter is: {'criterion': 'gini', 'max_depth': 8, 'max_leaf_nodes': 22, 'min_samples_split': 2}\n",
      "====================================================================================\n",
      "Below is f1 scores and best parameter for Linear Support Vector Machine\n",
      "f1 score for yelp Linear Support Vector Machine classifier test is: 0.25408289598519107\n",
      "f1 score for yelp Linear Support Vector Machine classifier train is: 0.23189004677273753\n",
      "f1 score for yelp Linear Support Vector Machine classifier valid is: 0.23966125643654448\n",
      "Best parameter is: {'C': 1.0, 'loss': 'hinge', 'max_iter': 45}\n",
      "====================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.23966125643654448"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1score2(GaussNbayes, yelpTest_freq, yelp_test[1], yelpTrain_freq, yelp_train[1], yelpValid_freq, yelp_valid[1], 'Naive Bayes')\n",
    "F1score2(DecisionTree, yelpTest_freq, yelp_test[1], yelpTrain_freq, yelp_train[1], yelpValid_freq, yelp_valid[1], 'Decision Tree')\n",
    "F1score2(svc, yelpTest_freq, yelp_test[1], yelpTrain_freq, yelp_train[1], yelpValid_freq, yelp_valid[1], 'Linear Support Vector Machine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4, do the same thing to imdb dataset Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is f1 scores and best parameter for uniform\n",
      "f1 score for imdb uniform classifier test is: 0.5014310369266095\n",
      "f1 score for imdb uniform classifier train is: 0.49586407652832204\n",
      "f1 score for imdb uniform classifier valid is: 0.4954868776136868\n",
      "====================================================================================\n",
      "Below is f1 scores and best parameter for majority frequent\n",
      "f1 score for imdb majority frequent classifier test is: 0.3333333333333333\n",
      "f1 score for imdb majority frequent classifier train is: 0.3333333333333333\n",
      "f1 score for imdb majority frequent classifier valid is: 0.3333333333333333\n",
      "====================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongjoon/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is f1 scores and best parameter for Naive Bayes\n",
      "f1 score for imdb Naive Bayes classifier test is: 0.8359549446896211\n",
      "f1 score for imdb Naive Bayes classifier train is: 0.874624832595253\n",
      "f1 score for imdb Naive Bayes classifier valid is: 0.8452683589267169\n",
      "Best parameter for Naive Bayes is: {'alpha': 0.2}\n",
      "====================================================================================\n",
      "Below is f1 scores and best parameter for Decision Tree\n",
      "f1 score for imdb Decision Tree classifier test is: 0.7243986733167429\n",
      "f1 score for imdb Decision Tree classifier train is: 0.7307857226619265\n",
      "f1 score for imdb Decision Tree classifier valid is: 0.7202767199353735\n",
      "Best parameter for Decision Tree is: {'criterion': 'gini', 'max_depth': 12, 'max_leaf_nodes': 22, 'min_samples_split': 2}\n",
      "====================================================================================\n",
      "Below is f1 scores and best parameter for Linear Support Vector Machine\n",
      "f1 score for imdb Linear Support Vector Machine classifier test is: 0.8513956269719808\n",
      "f1 score for imdb Linear Support Vector Machine classifier train is: 0.96198960981761\n",
      "f1 score for imdb Linear Support Vector Machine classifier valid is: 0.8636309631751073\n",
      "Best parameter for Linear Support Vector Machine is: {'C': 0.5, 'loss': 'squared_hinge', 'max_iter': 15}\n",
      "====================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8636309631751073"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1score4(uniform, imdbTest, imdb_test[1], imdbTrain, imdb_train[1], imdbValid, imdb_valid[1], 'uniform')\n",
    "F1score4(frequent, imdbTest, imdb_test[1], imdbTrain, imdb_train[1], imdbValid, imdb_valid[1], 'majority frequent')\n",
    "\n",
    "F1score3(Nbayes, imdbTest, imdb_test[1], imdbTrain, imdb_train[1], imdbValid, imdb_valid[1], 'Naive Bayes')\n",
    "F1score3(DecisionTree, imdbTest, imdb_test[1], imdbTrain, imdb_train[1], imdbValid, imdb_valid[1], 'Decision Tree')\n",
    "F1score3(svc, imdbTest, imdb_test[1], imdbTrain, imdb_train[1], imdbValid, imdb_valid[1], 'Linear Support Vector Machine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5, do the same thing to imdb dataset frequency Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is f1 scores and best parameter for Naive Bayes\n",
      "f1 score for imdb Naive Bayes classifier test is: 0.6388643134391188\n",
      "f1 score for imdb Naive Bayes classifier train is: 0.8685870455970421\n",
      "f1 score for imdb Naive Bayes classifier valid is: 0.7765259764644441\n",
      "Best parameter for Naive Bayes is: {}\n",
      "====================================================================================\n",
      "Below is f1 scores and best parameter for Decision Tree\n",
      "f1 score for imdb Decision Tree classifier test is: 0.41541847944062177\n",
      "f1 score for imdb Decision Tree classifier train is: 0.41959800798879177\n",
      "f1 score for imdb Decision Tree classifier valid is: 0.42078762338391085\n",
      "Best parameter for Decision Tree is: {'criterion': 'gini', 'max_depth': 12, 'max_leaf_nodes': 18, 'min_samples_split': 3}\n",
      "====================================================================================\n",
      "Below is f1 scores and best parameter for Linear Support Vector Machine\n",
      "f1 score for imdb Linear Support Vector Machine classifier test is: 0.6624099731565676\n",
      "f1 score for imdb Linear Support Vector Machine classifier train is: 0.6718681799783213\n",
      "f1 score for imdb Linear Support Vector Machine classifier valid is: 0.6624601146460078\n",
      "Best parameter for Linear Support Vector Machine is: {'C': 0.5, 'loss': 'hinge', 'max_iter': 15}\n",
      "====================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6624601146460078"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1score3(GaussNbayes, imdbTest_freq, imdb_test[1], imdbTrain_freq, imdb_train[1], imdbValid_freq, imdb_valid[1], 'Naive Bayes')\n",
    "F1score3(DecisionTree, imdbTest_freq, imdb_test[1], imdbTrain_freq, imdb_train[1], imdbValid_freq, imdb_valid[1], 'Decision Tree')\n",
    "F1score3(svc, imdbTest_freq, imdb_test[1], imdbTrain_freq, imdb_train[1], imdbValid_freq, imdb_valid[1], 'Linear Support Vector Machine')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
