{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "d76ab2ec5cfa3321526d36ec922f58e8df5c4108",
    "colab": {},
    "colab_type": "code",
    "id": "n8EtmiOTl3MP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongjoon/.local/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import color\n",
    "from skimage.feature import hog\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature\n",
    "\n",
    "def calc_hog_features(X, image_shape=(28, 28), pixels_per_cell=(8, 8)):\n",
    "    fd_list = []\n",
    "    for row in X:\n",
    "        img = row.reshape(image_shape)\n",
    "        fd = hog(img, orientations=8, pixels_per_cell=pixels_per_cell, cells_per_block=(1, 1))\n",
    "        fd_list.append(fd)\n",
    "    \n",
    "    return np.array(fd_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fbff0b11ab7fe7253c9f88cd0851a885feba0060",
    "colab_type": "text",
    "id": "q50m7w3WnFbX"
   },
   "source": [
    "## **Fetching MNIST dataset and applying HoG or PCA.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "98c8b98e6c4da052e3b56377f307f461a968d716",
    "colab": {},
    "colab_type": "code",
    "id": "I99-oJOHnCXG"
   },
   "outputs": [],
   "source": [
    "#Fetching MNIST dataset\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "pca = PCA(n_components=100, svd_solver='randomized',\n",
    "          whiten=True).fit(X)\n",
    "\n",
    "######### Comment out either of below two lines for PCA or HoG\n",
    "#X = calc_hog_features(X, pixels_per_cell=(8, 8))\n",
    "X = pca.transform(X)\n",
    "######### Comment out either of above two lines for PCA or HoG\n",
    "\n",
    "x_train, x_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "np.save('x_train', x_train)\n",
    "np.save('x_test', x_test)\n",
    "np.save('y_train', y_train)\n",
    "np.save('y_test', y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''param_list = [(\"eta\", 0.08), (\"max_depth\", 6), (\"subsample\", 0.8), (\"colsample_bytree\", 0.8), (\"objective\", \"multi:softmax\"), (\"eval_metric\", \"merror\"), (\"alpha\", 8), (\"lambda\", 2), (\"num_class\", 10)]\n",
    "n_rounds = 600\n",
    "early_stopping = 50\n",
    "    \n",
    "d_train = xgb.DMatrix(x_train, label=y_train)\n",
    "d_val = xgb.DMatrix(x_valid, label=y_valid)\n",
    "eval_list = [(d_train, \"train\"), (d_val, \"validation\")]\n",
    "bst = xgb.train(param_list, d_train, n_rounds, evals=eval_list, early_stopping_rounds=early_stopping, verbose_eval=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Trying different simple ML algorithms to see its performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "38ec6e42b634dde47f0819b4dcaf7ce5a5118db2",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "z6bj2EDZmrwD",
    "outputId": "4aba97bf-9554-4868-87fb-f9f90ecf0e8d"
   },
   "outputs": [],
   "source": [
    "#Training using ML algorithms\n",
    "#Instantiate simple machine learning models\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3)\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
    "    algorithm=\"SAMME.R\", learning_rate=0.5, random_state=42)\n",
    "\n",
    "log_clf = LogisticRegression(solver='lbfgs', multi_class='multinomial')\n",
    "ran_grid = [{'n_estimators':[50,100,150,200], 'max_depth':[9,10,11,12]}]\n",
    "ran_clf =  RandomForestClassifier(n_estimators = 200, max_depth=12)\n",
    "\n",
    "'''svc_clf = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svm_clf\", SVC(kernel=\"poly\", degree=7, C=0.5, gamma=0.05))\n",
    "    ])'''\n",
    "svc_clf = SVC(C=5,gamma=0.05)\n",
    "per_clf = Perceptron()\n",
    "nb_clf = GaussianNB()\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(random_state=42), n_estimators=100,\n",
    "    max_samples=100, bootstrap=True, n_jobs=-1, random_state=42)\n",
    "\n",
    "#SVC training\n",
    "svc_clf.fit(x_train, y_train)\n",
    "predicted = svc_clf.predict(x_test)\n",
    "print('SVC with degree=7 test accuracy : {}'.format(accuracy_score(y_test, predicted)))\n",
    "print('=============================================================================')\n",
    "'''\n",
    "#Gaussian Naive Bayes\n",
    "nb_clf.fit(x_train, y_train)\n",
    "nb_predicted = nb_clf.predict(x_test)\n",
    "print('Gaussian Naive Bayes test accuracy : {}'.format(accuracy_score(y_test, nb_predicted)))\n",
    "print('=============================================================================')\n",
    "\n",
    "#Bagging or trees\n",
    "bag_clf.fit(x_train, y_train)\n",
    "bag_pred = bag_clf.predict(x_test)\n",
    "print('Bagging decision tree test accuracy : {}'.format(accuracy_score(y_test, bag_pred)))\n",
    "print('=============================================================================')\n",
    "\n",
    "#Adaboosting of trees\n",
    "ada_clf.fit(x_train, y_train)\n",
    "ada_pred = ada_clf.predict(x_test)\n",
    "print('Adaboosted deceision tree test accuracy : {}'.format(accuracy_score(y_test, ada_pred)))\n",
    "print('=============================================================================')\n",
    "'''\n",
    "#Random Forrest regression\n",
    "ran_clf.fit(x_train, y_train)\n",
    "ran_predicted = ran_clf.predict(x_test)\n",
    "print('Random Forest test accuracy : {}'.format(accuracy_score(y_test, ran_predicted)))\n",
    "print('=============================================================================')\n",
    "\n",
    "#Perceptron\n",
    "per_clf.fit(x_train, y_train)\n",
    "per_predicted = per_clf.predict(x_test)\n",
    "print('Perceptron test accuracy: {}'.format(accuracy_score(y_test, per_predicted)))\n",
    "print('=============================================================================')\n",
    "\n",
    "#Logistic regression\n",
    "log_clf.fit(x_train, y_train)\n",
    "log_predicted = log_clf.predict(x_test)\n",
    "print('Logistic regression test accuracy : {}'.format(accuracy_score(y_test, log_predicted)))\n",
    "print('=============================================================================')\n",
    "\n",
    "#KNN\n",
    "knn_clf.fit(x_train, y_train)\n",
    "knn_predicted = knn_clf.predict(x_test)\n",
    "print('KNN test accuracy : {}'.format(accuracy_score(y_test, knn_predicted)))\n",
    "print('=============================================================================')\n",
    "\n",
    "# Train using simple ensemble voting classifier. Doesn't work well.\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', log_clf), \n",
    "        #('pf', per_clf),\n",
    "        #('nb', nb_clf),\n",
    "        #('ada', ada_clf),\n",
    "        #('bag', bag_clf),\n",
    "        #('rf', ran_clf), \n",
    "        ('svc', svc_clf),\n",
    "        ('knn', knn_clf)],\n",
    "    voting='hard')\n",
    "\n",
    "voting_clf.fit(x_train, y_train)\n",
    "\n",
    "train_predicted = voting_clf.predict(x_train)\n",
    "voting_predicted = voting_clf.predict(x_test)\n",
    "\n",
    "print('=============================================================================')\n",
    "print('Train accuracy for simple voting emsemble learning: {}'.format(accuracy_score(y_train, train_predicted)))\n",
    "print('Validation accuracy for simple voting emsemble learning: {}'.format(accuracy_score(y_test, voting_predicted)))\n",
    "print('=============================================================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9061459fdc7aa9f86777dcf23f42340d28c80a47"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', log_clf), \n",
    "        #('pf', per_clf),\n",
    "        #('nb', nb_clf),\n",
    "        #('ada', ada_clf),\n",
    "        #('bag', bag_clf),\n",
    "        #('rf', ran_clf), \n",
    "        ('svc', svc_clf),\n",
    "        ('knn', knn_clf)],\n",
    "    voting='hard')\n",
    "\n",
    "voting_clf.fit(x_train, y_train)\n",
    "\n",
    "train_predicted = voting_clf.predict(x_train)\n",
    "voting_predicted = voting_clf.predict(x_test)\n",
    "\n",
    "print('=============================================================================')\n",
    "print('Train accuracy for simple voting emsemble learning: {}'.format(accuracy_score(y_train, train_predicted)))\n",
    "print('Validation accuracy for simple voting emsemble learning: {}'.format(accuracy_score(y_test, voting_predicted)))\n",
    "print('=============================================================================')\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', log_clf), \n",
    "        ('pf', per_clf),\n",
    "        #('nb', nb_clf),\n",
    "        #('ada', ada_clf),\n",
    "        #('bag', bag_clf),\n",
    "        ('knn', knn_clf),\n",
    "        ('rf', ran_clf), \n",
    "        ('svc', svc_clf)],\n",
    "    voting='hard')\n",
    "\n",
    "voting_clf.fit(x_train, y_train)\n",
    "\n",
    "train_predicted = voting_clf.predict(x_train)\n",
    "voting_predicted = voting_clf.predict(x_test)\n",
    "\n",
    "print('=============================================================================')\n",
    "print('Train accuracy for simple voting emsemble learning: {}'.format(accuracy_score(y_train, train_predicted)))\n",
    "print('Validation accuracy for simple voting emsemble learning: {}'.format(accuracy_score(y_test, voting_predicted)))\n",
    "print('=============================================================================')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "project_mnist.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
